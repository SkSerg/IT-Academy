{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><center><h1>Биологический нейрон</h1></center></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Нейрон** — электрически возбудимая клетка, которая предназначена для приёма извне, обработки, хранения, передачи и вывода вовне информации с помощью электрических и химических сигналов.  \n",
    "  \n",
    "Типичный нейрон состоит из тела клетки, дендритов и одного аксона:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![neuron](images/neuron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простыми словами можно описать принцип действия нейрона следующим образом:\n",
    "- через дендриты в нейрон поступают сигналы (раздражители)\n",
    "- Если комбинация сигналов превышает пороговый уровень - нейрон \"выстреливает\", т.е. передаёт сигнал дальше через аксон."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейроны могут соединяться один с другим, формируя нервные сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><center><h1>Функции Активации (Activation Functions)</h1></center></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простейшим механизмом активации является **Step activation**, когда перспептрон передаёт на выход значение только в том случае, если сумма взвешенных входящих сигналов больше заданного порога:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![step](images/step_activation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При всей своей простоте, данная функция активации обладает критическим недостатком: она недифференцируемая.  Как результат, она не позволяет осуществлять процесс обучения персептрона.  \n",
    "  \n",
    "Для того, чтобы исправить это, было разработано множество других функций активаций, таких как:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![neuron](images/activation_functions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><center><h1>Задание 1 (2 балла)</h1></center></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите класс **ActivationFunction** и его подкласс **Sigmoid**, у которого будет функция `forward`, которая:\n",
    "- будет принимать на вход число и будет сохранять его внутри объекта\n",
    "- будет возвращать результат в соответствии с фукцией $\\sigma(x) = \\frac{1}{1 + e^{-x}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationFunction:\n",
    "    ...\n",
    "\n",
    "\n",
    "class Sigmoid(ActivationFunction):\n",
    "\n",
    "    def forward(self, value: float) -> float:\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><center><h1>Персептрон</h1></center></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Персептрон** -  математическая модель биологического нейрона, является базовым элементом нейронных сетей:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![neuron](images/perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Персептрон** состоит из следующих ключевых элементов:\n",
    "- `вход` - отвечает за получение входных значений. Является аналогом дендрита биологического нейрона\n",
    "- `веса` - механизм \"важности\" входных значений. По аналогии с нейроном - это \"толщина\" дендрита\n",
    "- `функция активации` - обрабатывает сумму взвешенных входных сигналов и передаёт результат на выход\n",
    "- `выход` - отвечает за передачу итогового результата. Аналогичен аксону\n",
    "  \n",
    "Практически всегда к входным сигналам также добавляется \"bias\", который всегда = 1.  \n",
    "Это позволяет не привязывать выход персептрона к 0 в случае, если все входные сигналы также равны 0 (как в механизме регрессии)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><center><h1>Задание 2 (4 балла)</h1></center></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "напишите класс **Layer**, у когорого будут следующие входные параметры:\n",
    "- **n_inputs** - количество входящих значений\n",
    "- **n_outputs** - количество исходящих значений (в нашем случае = 1)\n",
    "- **activation** - объект из семейства **ActivationFunction** (в нашем случае - **Sigmoid**)\n",
    "  \n",
    "При своём создании объект класса **Layer** должен также создавать атрибут `weights_`, в ктором будут рандомально инициализированны веса для входящих значений, а также для `bias`\n",
    "\n",
    "Класс **Layer** должен иметь функцию `forward`, принимающую на вход массив *numpy*, и возвращающую результат функции активации (тоже в виде массива).  \n",
    "Также эта функция должна сохранять полученные на вход значения внутри экземпляра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    def __init__(...):\n",
    "        ...\n",
    "\n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Layer(...)\n",
    "\n",
    "perceptron.forward(np.ndarray([1,2,3,4,5])) -> [0...1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><center><h1>Задание 3 (2 балла)</h1></center></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "напишите класс **LossFunction** и его подкласс **CrossEntropy**, у которого будет функция `loss`, которая будет принимать реальное бинарное значение *y_fact* и вероятность *y_prob* (оба параметра в виде np.array) и будет возвращать результат по формуле:  \n",
    "  \n",
    "$$\n",
    "L = - \\sum (y_{fact} * log(y_{prob}) + (1-y_{fact})*log(1-y_{prob}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunction:\n",
    "    ...\n",
    "\n",
    "class CrossEntropy (LossFunction):\n",
    "\n",
    "    def loss(self, y_fact: np.ndarray, y_prob: np.ndarray):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><center><h1>Обучение. Forward and Backpropagation</h1></center></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Процесс обучения персептрона (и в целом нейросети) итеративен и состоит из следующих этапов:\n",
    "- Сперва персептрон инициализируется с рандомальными весами\n",
    "- Осуществляется цикл \"вперёд\":\n",
    "  - Входные значения перемножаются с соответствующими весами и суммируются\n",
    "  - Эта сумма подаётся на функцию активации\n",
    "  - Функция активации возвращает итоговое значение\n",
    "- Итоговое значение сравнивается с ожидаемым и высчитывается ошибка (Loss)\n",
    "- Осуществляется цикл \"назад\":\n",
    "  - при помощи `Chain Rule` рассчитываются частичные производные для всех элементов персептрона\n",
    "  - исходя из заданного коэффициента обучения (`learning rate`, $\\alpha$), веса $w_{i}$ корректируются\n",
    "- Данный цикл повторяется заданное количество раз или до тех пор, пока итоговая ошибка не опустится ниже заданного порогового значения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Chain Rule</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если нам дана функция $y=f(u)$, где $u = g(x)$, то тогда производная этой функции по $x$ будет равно:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{dy}{dx} = \\frac{dy}{du}\\frac{du}{dx}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда для того, чтобы понять, насколько изменение весов $w$ влияет на изменение $y$ (т.е. производные $\\frac{dy}{dw_{i}}$), можно вычислить следующие производные:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![neuron](images/backpropagation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><center><h1>Задание 4 (8 баллов)</h1></center></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модифицируйте классы **Layer**, **LossFuncton** и **ActivationFunction** таким образом, чтобы можно было рассчитать их частичные производные, и добавьте функцию `back`, позволяющую осуществить backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><center><h3>Это задание очень сложное, и даже частичное его выполнение будет учитываться</h3></center></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000, Loss: 0.6632\n",
      "Epoch 200/1000, Loss: 0.6159\n",
      "Epoch 300/1000, Loss: 0.6140\n",
      "Epoch 400/1000, Loss: 0.6139\n",
      "Epoch 500/1000, Loss: 0.6139\n",
      "Epoch 600/1000, Loss: 0.6139\n",
      "Epoch 700/1000, Loss: 0.6139\n",
      "Epoch 800/1000, Loss: 0.6139\n",
      "Epoch 900/1000, Loss: 0.6139\n",
      "Epoch 1000/1000, Loss: 0.6139\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Формирование функции активации\n",
    "class ActivationFunction:\n",
    "    def forward(self, x: np.ndarray):\n",
    "        pass\n",
    "    \n",
    "    def gradient(self, x: np.ndarray):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Sigmoid(ActivationFunction):\n",
    "    # Расчёт значения функции активации\n",
    "    def forward(self, x: np.ndarray):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "     # Расчёт градиента функции активации\n",
    "    def gradient(self, x: np.ndarray):\n",
    "        sigmoid = self.forward(x)\n",
    "        return sigmoid * (1 - sigmoid)\n",
    "\n",
    "# Формирование модели\n",
    "class Layer:\n",
    "    def __init__(self, n_inputs: int, n_outputs: int, activation):\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.activation = activation\n",
    "        self.weights_ = np.random.randn(n_inputs, n_outputs)\n",
    "        self.bias_ = np.random.randn(n_outputs)\n",
    "        \n",
    "    # Прямое распространение\n",
    "    def forward(self, inputs: np.ndarray):\n",
    "        self.inputs_ = inputs\n",
    "\n",
    "        return self.activation.forward(np.dot(inputs, self.weights_) + self.bias_)\n",
    "    # Обратное распространение    \n",
    "    def back(self, grad_outputs: float, learning_rate: float):\n",
    "        grad_inputs = grad_outputs * self.activation.gradient(self.inputs_)\n",
    "        self.grad_weights_ = np.dot(self.inputs_.T, grad_inputs)\n",
    "        self.grad_bias_ = np.sum(grad_inputs, axis=0)\n",
    "        self.weights_ -= learning_rate * self.grad_weights_\n",
    "        self.bias_ -= learning_rate * self.grad_bias_\n",
    "\n",
    "        return grad_inputs @ self.weights_\n",
    "\n",
    "\n",
    "# Формирование функции потерь\n",
    "class LossFunction:\n",
    "    def loss(self, y_fact: np.ndarray, y_prob: np.ndarray):\n",
    "        pass\n",
    "    \n",
    "    def gradient(self, y_fact: np.ndarray, y_prob: np.ndarray):\n",
    "        pass\n",
    "\n",
    "\n",
    "class CrossEntropy(LossFunction):\n",
    "    # Расчёт значения функции потерь    \n",
    "    def loss(self, y_fact: np.ndarray, y_prob: np.ndarray):\n",
    "        loss_values=-np.sum(y_fact * np.log(y_prob) + (1 - y_fact) * np.log(1 - y_prob))\n",
    "\n",
    "        return loss_values \n",
    "    # Расчёт градиента функции потерь   \n",
    "    def gradient(self, y_fact: np.ndarray, y_prob: np.ndarray):\n",
    "\n",
    "        return -np.sum(y_fact/y_prob) + np.sum((1-y_fact)/(1-y_prob))\n",
    "\n",
    "\n",
    "#  Задание параметров модели\n",
    "input_dim = 2\n",
    "output_dim = 1\n",
    "learning_rate = 0.1\n",
    "epochs = 500\n",
    "\n",
    "activation = Sigmoid()\n",
    "loss_func = CrossEntropy()\n",
    "model = Layer(input_dim, output_dim, activation)\n",
    "\n",
    "# Задание входных данных\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [0], [0], [1]])\n",
    "\n",
    "def train_model(X, y, model, loss_func, learning_rate: float, epochs: int):\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(len(X)):\n",
    "            # Прямое распространение\n",
    "            outputs = model.forward(X[i])\n",
    "\n",
    "            # Вычисление функции потерь\n",
    "            loss = loss_func.loss(y[i], outputs)\n",
    "\n",
    "            # Вычисление градиента функции потерь\n",
    "            grad_loss = loss_func.gradient(y[i], outputs)\n",
    "\n",
    "            # Обратное распространение\n",
    "            model.back(grad_loss, learning_rate)\n",
    "\n",
    "        # Вывод информации о прогрессе обучения\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "# Обучение модели\n",
    "train_model(X, y, model, loss_func, learning_rate, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Удачи!</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
